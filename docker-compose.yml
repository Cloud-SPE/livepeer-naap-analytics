services:
  ### webserver ###
  webserver:
    image: tztcloud/livepeer-rtav-test-ui:latest
    container_name: live-video-to-video-webserver
    ports:
      - 8088:8088

  ###  INGEST  ###
  mediamtx:
    image: livepeerci/mediamtx
    container_name: live-video-to-video-mediamtx
    volumes:
      - ./configs/mediamtx/mediamtx.yml:/mediamtx.yml
    environment:
      - MTX_WEBRTCADDITIONALHOSTS=${HOST}
    ports:
      - 8890:8890
      - 9997:9997
      - 1935:1935

  gateway:
    image: livepeer/go-livepeer:latest
    container_name: live-video-to-video-gateway
    volumes:
      - ./data/gateway:/data
    ports:
      - 5937:5937
      - 7280:7280
    environment:
      - LIVE_AI_ALLOW_CORS=1
      - LIVE_AI_WHIP_ADDR=gateway:7280
      - LIVE_AI_GATHER_TIMEOUT=5
      - LIVE_AI_MIN_SEG_DUR=1s
      - LIVE_AI_NAT_IP=${HOST_IP}
      - LIVE_AI_PLAYBACK_HOST=rtmp://mediamtx:1935/
      - LIVE_AI_WHEP_URL=https://${HOST}/mediamtx/
    command: ["-gateway",
              "-orchAddr=${ORCH_SERVICE_ADDR}",
              "-rtmpAddr=gateway:1937",
              "-httpAddr=gateway:5937",
              "-httpIngest=true",
              "-v=9",
              "-network=arbitrum-one-mainnet",
              "-blockPollingInterval=10",
              "-ethUrl=${ARB_ETH_URL}",
              "-ethPassword=/data/eth-secret.txt",
              "-ethKeystorePath=/data/",
              "-dataDir=/data/tmp",
              "-monitor",
              "-kafkaBootstrapServers=kafka:9092",
              "-kafkaGatewayTopic=streaming_events" ]

  ####  Monitoring  ####
  kafka:
    image: apache/kafka:3.9.0
    container_name: live-video-to-video-kafka
    ports:
      - 9092:9092
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@127.0.0.1:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092,CONTROLLER://127.0.0.1:9093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB segments
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'
    volumes:
      - ./data/kafka:/var/lib/kafka/data
    healthcheck:
      test: /opt/kafka/bin/kafka-cluster.sh cluster-id --bootstrap-server kafka:9092 || exit 1
      interval: 1s
      timeout: 60s
      retries: 60

  kafka-sse-api:
    image: ghcr.io/aklivity/zilla:latest
    container_name: live-video-to-video-kafka-sse-api
    ports:
      - 7114:7114
    environment:
      KAFKA_BOOTSTRAP_SERVER: kafka:9092
      ZILLA_INCUBATOR_ENABLED: "true"
    volumes:
      - ./configs/zilla:/etc/zilla
      - ./configs/zilla/index.html:/var/www/index.html
    command: start -v -e
    depends_on:
      kafka:
        condition: service_healthy
        restart: true

  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui:latest
    container_name: live-video-to-video-kafka-ui
    ports:
      - 8080:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: live-video-to-video
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      kafka:
        condition: service_healthy
        restart: true

  kafka-init:
    image: apache/kafka:3.9.0
    container_name: live-video-to-video-kafka-init
    command:
      - /bin/sh
      - -c
      - |
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic streaming_events --partitions 1 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic streaming_events_dlq --partitions 1 --replication-factor 1
    depends_on:
      kafka:
        condition: service_healthy
        restart: true
    init: true

  ### KAFKA CONNECT (for ClickHouse and MinIO sinks) ###
  connect:
    image: confluentinc/cp-kafka-connect:7.8.0
    container_name: livepeer-analytics-connect
    depends_on:
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      minio:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: livepeer-analytics-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    volumes:
      - ./configs/connect:/etc/kafka-connect/configs:ro
    command:
      - /bin/bash
      - -c
      - |
        # Install ClickHouse JDBC connector
        confluent-hub install --no-prompt clickhouse/clickhouse-kafka-connect:latest
        # Install S3 connector for MinIO
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:latest
        /etc/confluent/docker/run
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 10s
      timeout: 5s
      retries: 10

  ### STREAM PROCESSING ###
  flink-builder:
    image: maven:3.9-eclipse-temurin-11
    container_name: livepeer-analytics-flink-builder
    working_dir: /build
    volumes:
      - ./flink-jobs:/build
      - flink-maven-cache:/root/.m2
    command: >
      sh -c "
        echo 'Building Flink jobs...';
        mvn clean package;
        echo 'Build complete. Copying JAR to output directory...';
        mkdir -p /build/output;
        cp target/*.jar /build/output/ 2>/dev/null || echo 'Warning: No JAR files found in target/';
        ls -lh /build/output/;
      "
    init: true

  flink-jobmanager:
    image: flink:1.20.3-java11
    container_name: livepeer-analytics-flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
        state.backend: rocksdb
        state.checkpoints.dir: file:////flink-tmp/checkpoints
        state.savepoints.dir: file:////flink-tmp/savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        execution.checkpointing.min-pause: 30000
        execution.checkpointing.timeout: 600000
    volumes:
      - ./data/flink/tmp:/flink-tmp
      - ./flink-jobs/output:/opt/flink/usrlib
    depends_on:
      flink-builder:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081/overview" ]
      interval: 10s
      timeout: 5s
      retries: 5

  flink-taskmanager:
    image: flink:1.20.3-java11
    container_name: livepeer-analytics-flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
        state.backend: rocksdb
        state.backend.incremental: true
    volumes:
      - ./data/flink/tmp/checkpoints:/tmp/flink-checkpoints
      - ./data/flink/tmp/savepoints:/tmp/flink-savepoints
      - ./flink-jobs/output:/opt/flink/usrlib
    scale: 1

  flink-job-submitter:
    image: flink:1.20.3-java11
    container_name: livepeer-analytics-flink-job-submitter
    depends_on:
      flink-jobmanager:
        condition: service_started
      flink-taskmanager:
        condition: service_started
      connect-init:
        condition: service_completed_successfully
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    volumes:
      - ./flink-jobs/output:/opt/flink/usrlib
      - ./flink-jobs/:/jobs/
    command: >
      sh -c "
        echo 'Waiting for Flink cluster to be ready...';
        sleep 30;
        echo 'Submitting Flink jobs...';
        /bin/bash /jobs/submit-jobs.sh;
        echo 'Job submission complete.';
      "
    init: true

  ### ANALYTICS STORAGE ###
  clickhouse:
    image: clickhouse/clickhouse-server:24.11
    container_name: livepeer-analytics-clickhouse
    ports:
      - "8123:8123"
    volumes:
      - ./data/clickhouse:/var/lib/clickhouse
      - ./configs/clickhouse-users:/etc/clickhouse-server/users.d
      - ./configs/clickhouse-init:/docker-entrypoint-initdb.d
    environment:
      CLICKHOUSE_DB: livepeer_analytics
      CLICKHOUSE_USER: analytics_user
      CLICKHOUSE_PASSWORD: analytics_password
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: live-video-to-video-minio
    ports:
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - ./data/minio:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio-init:
    image: minio/mc:latest
    container_name: live-video-to-video-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/streaming-events --ignore-existing;
      mc anonymous set download myminio/streaming-events;
      echo 'MinIO buckets created';
      "
    init: true

  ### KAFKA CONNECT SINK INITIALIZATION ###
  connect-init:
    image: curlimages/curl:latest
    container_name: livepeer-analytics-connect-init
    volumes:
      - ./configs/connect:/configs:ro
    depends_on:
      connect:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for Kafka Connect to be fully ready..."
        while [ $$(curl -s -o /dev/null -w %{http_code} http://connect:8083/connectors) -eq 000 ] ; do 
          sleep 5 
        done
        echo "Kafka Connect is up!"
        
        echo ""
        echo "=========================================="
        echo "Registering ClickHouse Sink for Raw Events..."
        echo "=========================================="
        curl -s -X POST http://connect:8083/connectors \
          -H "Content-Type: application/json" \
          -d @/configs/clickhouse-sink.json
        
        echo ""
        echo "ClickHouse sink configured!"
        echo ""
        
        echo "=========================================="
        echo "Registering MinIO S3 Sink for Raw Events..."
        echo "=========================================="
        curl -s -X POST http://connect:8083/connectors \
          -H "Content-Type: application/json" \
          -d @/configs/minio-sink.json
        
        echo ""
        echo "MinIO sink registered successfully!"
        echo ""
        echo "=========================================="
        echo "All Kafka Connect sinks configured!"
        echo "=========================================="
    init: true

  ### VISUALIZATION ###
  grafana:
    image: grafana/grafana:latest
    container_name: livepeer-analytics-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-clickhouse-datasource
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioning/dashboards/naap-overview.json
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./configs/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  flink-maven-cache:

networks:
  default:
    name: live-video-to-video